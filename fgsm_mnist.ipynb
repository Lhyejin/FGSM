{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FGSM_MNIST_복사본.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQfIRBcwatMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import easydict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTRfLl3rKPtr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NetDrop(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NetDrop, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "    self.dropout1 = nn.Dropout2d(0.25)\n",
        "    self.dropout2 = nn.Dropout2d(0.5)\n",
        "    self.fc1 = nn.Linear(9216, 128)\n",
        "    self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, 2)\n",
        "    x = self.dropout1(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.dropout2(x)\n",
        "    output = self.fc2(x)\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSnsGERkiSns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NetConv(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NetConv, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "    self.fc1 = nn.Linear(36864, 128)\n",
        "    self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    output = self.fc2(x)\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYHv8DhZmu0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.fc1 = nn.Linear(28*28, 500)\n",
        "    self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    output = self.fc2(x)\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUVmMlC1LF6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(args, model, device, train_loader, optimizer):\n",
        "  model.train()\n",
        "  # cross entropy loss\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  for epoch in range(1, args.epochs + 1):\n",
        "    for batch_idx, (image, target) in enumerate(train_loader):\n",
        "      image, target = image.to(device), target.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      output = model(image)\n",
        "      \n",
        "      loss = criterion(output, target)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      if batch_idx % args.log_interval == 0:\n",
        "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "            epoch, batch_idx * len(image), len(train_loader.dataset),\n",
        "            100. * batch_idx / len(train_loader), loss.item()))\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsHtkxuGVVgZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(args, model, device, test_loader):\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  adv_correct = 0\n",
        "  misclassified = 0\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  for images, targets in test_loader:\n",
        "    images = Variable(images.to(device), requires_grad=True)\n",
        "    targets = Variable(targets.to(device))\n",
        "   \n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, targets)\n",
        "    test_loss += loss\n",
        "    loss.backward()\n",
        "\n",
        "\t\t# Generate perturbation\n",
        "    grad = torch.sign(images.grad.data)\n",
        "    adv_images = torch.clamp(images.data + args.epsilon * grad, 0, 1)\n",
        "\n",
        "    adv_outputs = model(Variable(adv_images))\n",
        "\n",
        "    _, pred = torch.max(outputs.data, 1)\n",
        "    _, adv_preds = torch.max(adv_outputs.data, 1)\n",
        "\n",
        "    correct += (pred == targets).sum().item()\n",
        "    adv_correct += (adv_preds == targets).sum().item()\n",
        "    misclassified += (pred != adv_preds).sum().item()\n",
        "\n",
        "\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "\n",
        "  print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f})\\n'.format(\n",
        "      test_loss, correct, len(test_loader.dataset),\n",
        "      100. * correct / len(test_loader.dataset)))\n",
        "  print('\\nAdversarial Test: Accuracy: {}/{} ({:.0f})\\n'.format(\n",
        "      adv_correct, len(test_loader.dataset),\n",
        "      100. * adv_correct / len(test_loader.dataset)))\n",
        "  print('\\nmisclassified examples : {}/ {}\\n'.format(\n",
        "      misclassified, len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsGjB2jagK5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(network='fc', data_normalize=False):\n",
        "  # args = parser.parse_args()\n",
        "  args = easydict.EasyDict({\n",
        "      'batch_size': 64,\n",
        "      'test_batch_size': 1000,\n",
        "      'epochs': 5,\n",
        "      'lr': 0.001,\n",
        "      'gamma': 0.7,\n",
        "      'no_cuda': False,\n",
        "      'log_interval': 64,\n",
        "      'epsilon': 0.25\n",
        "  })\n",
        "  use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "  \n",
        "  transformation = transforms.ToTensor()\n",
        "  if data_normalize:\n",
        "    transformation = transforms.Compose([transforms.ToTensor(), \n",
        "                                         transforms.Normalize((0.1307,),(0.3081,))])  \n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      datasets.MNIST('data/', train=True, download=True,\n",
        "                      transform=transformation),\n",
        "      batch_size=args.batch_size, shuffle=True)\n",
        "  test_loader = torch.utils.data.DataLoader(\n",
        "      datasets.MNIST('data/', train=False, download=True,\n",
        "                     transform=transformation),\n",
        "      batch_size=args.test_batch_size, shuffle=True)\n",
        "  \n",
        "  if network == 'conv':\n",
        "    model = NetConv().to(device)\n",
        "  elif network == 'drop':\n",
        "    model = NetDrop().to(device)\n",
        "  elif network == 'fc':\n",
        "    model = Net().to(device)\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr= args.lr)\n",
        "\n",
        "  train(args, model, device, train_loader, optimizer)\n",
        "\n",
        "  test(args, model, device, test_loader)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQddq2gYXzHi",
        "colab_type": "code",
        "outputId": "d3dc2ae9-79b6-418b-b05d-34ed6c4ce310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# default - fc net\n",
        "if __name__ == '__main__': \n",
        "  main()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.311231\n",
            "Train Epoch: 1 [4096/60000 (7%)]\tLoss: 0.279794\n",
            "Train Epoch: 1 [8192/60000 (14%)]\tLoss: 0.489381\n",
            "Train Epoch: 1 [12288/60000 (20%)]\tLoss: 0.322116\n",
            "Train Epoch: 1 [16384/60000 (27%)]\tLoss: 0.249513\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.206595\n",
            "Train Epoch: 1 [24576/60000 (41%)]\tLoss: 0.283793\n",
            "Train Epoch: 1 [28672/60000 (48%)]\tLoss: 0.132506\n",
            "Train Epoch: 1 [32768/60000 (55%)]\tLoss: 0.350946\n",
            "Train Epoch: 1 [36864/60000 (61%)]\tLoss: 0.355547\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.200195\n",
            "Train Epoch: 1 [45056/60000 (75%)]\tLoss: 0.216296\n",
            "Train Epoch: 1 [49152/60000 (82%)]\tLoss: 0.092850\n",
            "Train Epoch: 1 [53248/60000 (89%)]\tLoss: 0.071636\n",
            "Train Epoch: 1 [57344/60000 (96%)]\tLoss: 0.125348\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.117366\n",
            "Train Epoch: 2 [4096/60000 (7%)]\tLoss: 0.066372\n",
            "Train Epoch: 2 [8192/60000 (14%)]\tLoss: 0.100264\n",
            "Train Epoch: 2 [12288/60000 (20%)]\tLoss: 0.102073\n",
            "Train Epoch: 2 [16384/60000 (27%)]\tLoss: 0.234614\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.062606\n",
            "Train Epoch: 2 [24576/60000 (41%)]\tLoss: 0.109893\n",
            "Train Epoch: 2 [28672/60000 (48%)]\tLoss: 0.144235\n",
            "Train Epoch: 2 [32768/60000 (55%)]\tLoss: 0.042856\n",
            "Train Epoch: 2 [36864/60000 (61%)]\tLoss: 0.066794\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.132492\n",
            "Train Epoch: 2 [45056/60000 (75%)]\tLoss: 0.037765\n",
            "Train Epoch: 2 [49152/60000 (82%)]\tLoss: 0.142443\n",
            "Train Epoch: 2 [53248/60000 (89%)]\tLoss: 0.068107\n",
            "Train Epoch: 2 [57344/60000 (96%)]\tLoss: 0.026990\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.155628\n",
            "Train Epoch: 3 [4096/60000 (7%)]\tLoss: 0.048453\n",
            "Train Epoch: 3 [8192/60000 (14%)]\tLoss: 0.036868\n",
            "Train Epoch: 3 [12288/60000 (20%)]\tLoss: 0.018828\n",
            "Train Epoch: 3 [16384/60000 (27%)]\tLoss: 0.027918\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.020977\n",
            "Train Epoch: 3 [24576/60000 (41%)]\tLoss: 0.043909\n",
            "Train Epoch: 3 [28672/60000 (48%)]\tLoss: 0.037240\n",
            "Train Epoch: 3 [32768/60000 (55%)]\tLoss: 0.063378\n",
            "Train Epoch: 3 [36864/60000 (61%)]\tLoss: 0.012645\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.022703\n",
            "Train Epoch: 3 [45056/60000 (75%)]\tLoss: 0.062359\n",
            "Train Epoch: 3 [49152/60000 (82%)]\tLoss: 0.029329\n",
            "Train Epoch: 3 [53248/60000 (89%)]\tLoss: 0.042197\n",
            "Train Epoch: 3 [57344/60000 (96%)]\tLoss: 0.152317\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.019384\n",
            "Train Epoch: 4 [4096/60000 (7%)]\tLoss: 0.128748\n",
            "Train Epoch: 4 [8192/60000 (14%)]\tLoss: 0.015746\n",
            "Train Epoch: 4 [12288/60000 (20%)]\tLoss: 0.016530\n",
            "Train Epoch: 4 [16384/60000 (27%)]\tLoss: 0.009318\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.048745\n",
            "Train Epoch: 4 [24576/60000 (41%)]\tLoss: 0.013341\n",
            "Train Epoch: 4 [28672/60000 (48%)]\tLoss: 0.027921\n",
            "Train Epoch: 4 [32768/60000 (55%)]\tLoss: 0.027066\n",
            "Train Epoch: 4 [36864/60000 (61%)]\tLoss: 0.004874\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.013438\n",
            "Train Epoch: 4 [45056/60000 (75%)]\tLoss: 0.115197\n",
            "Train Epoch: 4 [49152/60000 (82%)]\tLoss: 0.042617\n",
            "Train Epoch: 4 [53248/60000 (89%)]\tLoss: 0.049378\n",
            "Train Epoch: 4 [57344/60000 (96%)]\tLoss: 0.044467\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.050805\n",
            "Train Epoch: 5 [4096/60000 (7%)]\tLoss: 0.021950\n",
            "Train Epoch: 5 [8192/60000 (14%)]\tLoss: 0.020000\n",
            "Train Epoch: 5 [12288/60000 (20%)]\tLoss: 0.015182\n",
            "Train Epoch: 5 [16384/60000 (27%)]\tLoss: 0.074589\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.088121\n",
            "Train Epoch: 5 [24576/60000 (41%)]\tLoss: 0.084114\n",
            "Train Epoch: 5 [28672/60000 (48%)]\tLoss: 0.103960\n",
            "Train Epoch: 5 [32768/60000 (55%)]\tLoss: 0.003093\n",
            "Train Epoch: 5 [36864/60000 (61%)]\tLoss: 0.022109\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.006398\n",
            "Train Epoch: 5 [45056/60000 (75%)]\tLoss: 0.007780\n",
            "Train Epoch: 5 [49152/60000 (82%)]\tLoss: 0.029695\n",
            "Train Epoch: 5 [53248/60000 (89%)]\tLoss: 0.029297\n",
            "Train Epoch: 5 [57344/60000 (96%)]\tLoss: 0.042587\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy: 9783/10000 (98)\n",
            "\n",
            "\n",
            "Adversarial Test: Accuracy: 86/10000 (1)\n",
            "\n",
            "\n",
            "misclassified examples : 9733/ 10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PWAYqDXnk4U",
        "colab_type": "code",
        "outputId": "10b82d73-4291-4a2a-eecc-ace2fba67b88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# use convolutioal network model\n",
        "if __name__ == '__main__':\n",
        "  main(network='conv')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.305729\n",
            "Train Epoch: 1 [4096/60000 (7%)]\tLoss: 0.380430\n",
            "Train Epoch: 1 [8192/60000 (14%)]\tLoss: 0.171780\n",
            "Train Epoch: 1 [12288/60000 (20%)]\tLoss: 0.103520\n",
            "Train Epoch: 1 [16384/60000 (27%)]\tLoss: 0.279369\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.110197\n",
            "Train Epoch: 1 [24576/60000 (41%)]\tLoss: 0.032505\n",
            "Train Epoch: 1 [28672/60000 (48%)]\tLoss: 0.075675\n",
            "Train Epoch: 1 [32768/60000 (55%)]\tLoss: 0.186955\n",
            "Train Epoch: 1 [36864/60000 (61%)]\tLoss: 0.007782\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.051641\n",
            "Train Epoch: 1 [45056/60000 (75%)]\tLoss: 0.015174\n",
            "Train Epoch: 1 [49152/60000 (82%)]\tLoss: 0.066235\n",
            "Train Epoch: 1 [53248/60000 (89%)]\tLoss: 0.172327\n",
            "Train Epoch: 1 [57344/60000 (96%)]\tLoss: 0.007114\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.043671\n",
            "Train Epoch: 2 [4096/60000 (7%)]\tLoss: 0.006706\n",
            "Train Epoch: 2 [8192/60000 (14%)]\tLoss: 0.012339\n",
            "Train Epoch: 2 [12288/60000 (20%)]\tLoss: 0.005360\n",
            "Train Epoch: 2 [16384/60000 (27%)]\tLoss: 0.007608\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.084034\n",
            "Train Epoch: 2 [24576/60000 (41%)]\tLoss: 0.012902\n",
            "Train Epoch: 2 [28672/60000 (48%)]\tLoss: 0.001803\n",
            "Train Epoch: 2 [32768/60000 (55%)]\tLoss: 0.018252\n",
            "Train Epoch: 2 [36864/60000 (61%)]\tLoss: 0.030321\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.077490\n",
            "Train Epoch: 2 [45056/60000 (75%)]\tLoss: 0.075269\n",
            "Train Epoch: 2 [49152/60000 (82%)]\tLoss: 0.002380\n",
            "Train Epoch: 2 [53248/60000 (89%)]\tLoss: 0.007244\n",
            "Train Epoch: 2 [57344/60000 (96%)]\tLoss: 0.001600\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.031771\n",
            "Train Epoch: 3 [4096/60000 (7%)]\tLoss: 0.056755\n",
            "Train Epoch: 3 [8192/60000 (14%)]\tLoss: 0.006547\n",
            "Train Epoch: 3 [12288/60000 (20%)]\tLoss: 0.004237\n",
            "Train Epoch: 3 [16384/60000 (27%)]\tLoss: 0.012547\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.006838\n",
            "Train Epoch: 3 [24576/60000 (41%)]\tLoss: 0.000900\n",
            "Train Epoch: 3 [28672/60000 (48%)]\tLoss: 0.028462\n",
            "Train Epoch: 3 [32768/60000 (55%)]\tLoss: 0.094858\n",
            "Train Epoch: 3 [36864/60000 (61%)]\tLoss: 0.017786\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.038644\n",
            "Train Epoch: 3 [45056/60000 (75%)]\tLoss: 0.002704\n",
            "Train Epoch: 3 [49152/60000 (82%)]\tLoss: 0.000519\n",
            "Train Epoch: 3 [53248/60000 (89%)]\tLoss: 0.006123\n",
            "Train Epoch: 3 [57344/60000 (96%)]\tLoss: 0.000573\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.008969\n",
            "Train Epoch: 4 [4096/60000 (7%)]\tLoss: 0.000219\n",
            "Train Epoch: 4 [8192/60000 (14%)]\tLoss: 0.007273\n",
            "Train Epoch: 4 [12288/60000 (20%)]\tLoss: 0.003058\n",
            "Train Epoch: 4 [16384/60000 (27%)]\tLoss: 0.005615\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.000829\n",
            "Train Epoch: 4 [24576/60000 (41%)]\tLoss: 0.019173\n",
            "Train Epoch: 4 [28672/60000 (48%)]\tLoss: 0.003692\n",
            "Train Epoch: 4 [32768/60000 (55%)]\tLoss: 0.001832\n",
            "Train Epoch: 4 [36864/60000 (61%)]\tLoss: 0.009756\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.001780\n",
            "Train Epoch: 4 [45056/60000 (75%)]\tLoss: 0.001942\n",
            "Train Epoch: 4 [49152/60000 (82%)]\tLoss: 0.001044\n",
            "Train Epoch: 4 [53248/60000 (89%)]\tLoss: 0.055160\n",
            "Train Epoch: 4 [57344/60000 (96%)]\tLoss: 0.001066\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.002790\n",
            "Train Epoch: 5 [4096/60000 (7%)]\tLoss: 0.001403\n",
            "Train Epoch: 5 [8192/60000 (14%)]\tLoss: 0.000527\n",
            "Train Epoch: 5 [12288/60000 (20%)]\tLoss: 0.000810\n",
            "Train Epoch: 5 [16384/60000 (27%)]\tLoss: 0.015567\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.000259\n",
            "Train Epoch: 5 [24576/60000 (41%)]\tLoss: 0.000417\n",
            "Train Epoch: 5 [28672/60000 (48%)]\tLoss: 0.000778\n",
            "Train Epoch: 5 [32768/60000 (55%)]\tLoss: 0.000170\n",
            "Train Epoch: 5 [36864/60000 (61%)]\tLoss: 0.000634\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.038631\n",
            "Train Epoch: 5 [45056/60000 (75%)]\tLoss: 0.006728\n",
            "Train Epoch: 5 [49152/60000 (82%)]\tLoss: 0.003940\n",
            "Train Epoch: 5 [53248/60000 (89%)]\tLoss: 0.014841\n",
            "Train Epoch: 5 [57344/60000 (96%)]\tLoss: 0.000935\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 9876/10000 (99)\n",
            "\n",
            "\n",
            "Adversarial Test: Accuracy: 3152/10000 (32)\n",
            "\n",
            "\n",
            "misclassified examples : 6727/ 10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l97Xv-OYo1RV",
        "colab_type": "code",
        "outputId": "b8de4ca2-7885-4f01-aa5a-132cddde17d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# use dropout network model\n",
        "if __name__ == '__main__':\n",
        "  main(network='drop')\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.307730\n",
            "Train Epoch: 1 [4096/60000 (7%)]\tLoss: 0.475542\n",
            "Train Epoch: 1 [8192/60000 (14%)]\tLoss: 0.290257\n",
            "Train Epoch: 1 [12288/60000 (20%)]\tLoss: 0.190670\n",
            "Train Epoch: 1 [16384/60000 (27%)]\tLoss: 0.249261\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.328419\n",
            "Train Epoch: 1 [24576/60000 (41%)]\tLoss: 0.100960\n",
            "Train Epoch: 1 [28672/60000 (48%)]\tLoss: 0.098544\n",
            "Train Epoch: 1 [32768/60000 (55%)]\tLoss: 0.088276\n",
            "Train Epoch: 1 [36864/60000 (61%)]\tLoss: 0.104067\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.110589\n",
            "Train Epoch: 1 [45056/60000 (75%)]\tLoss: 0.040688\n",
            "Train Epoch: 1 [49152/60000 (82%)]\tLoss: 0.136981\n",
            "Train Epoch: 1 [53248/60000 (89%)]\tLoss: 0.064971\n",
            "Train Epoch: 1 [57344/60000 (96%)]\tLoss: 0.052227\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.137582\n",
            "Train Epoch: 2 [4096/60000 (7%)]\tLoss: 0.023206\n",
            "Train Epoch: 2 [8192/60000 (14%)]\tLoss: 0.096942\n",
            "Train Epoch: 2 [12288/60000 (20%)]\tLoss: 0.273607\n",
            "Train Epoch: 2 [16384/60000 (27%)]\tLoss: 0.041753\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.071983\n",
            "Train Epoch: 2 [24576/60000 (41%)]\tLoss: 0.035051\n",
            "Train Epoch: 2 [28672/60000 (48%)]\tLoss: 0.063576\n",
            "Train Epoch: 2 [32768/60000 (55%)]\tLoss: 0.087869\n",
            "Train Epoch: 2 [36864/60000 (61%)]\tLoss: 0.443689\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.071902\n",
            "Train Epoch: 2 [45056/60000 (75%)]\tLoss: 0.089983\n",
            "Train Epoch: 2 [49152/60000 (82%)]\tLoss: 0.072849\n",
            "Train Epoch: 2 [53248/60000 (89%)]\tLoss: 0.057858\n",
            "Train Epoch: 2 [57344/60000 (96%)]\tLoss: 0.155150\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.081289\n",
            "Train Epoch: 3 [4096/60000 (7%)]\tLoss: 0.069045\n",
            "Train Epoch: 3 [8192/60000 (14%)]\tLoss: 0.088416\n",
            "Train Epoch: 3 [12288/60000 (20%)]\tLoss: 0.123582\n",
            "Train Epoch: 3 [16384/60000 (27%)]\tLoss: 0.049053\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.108951\n",
            "Train Epoch: 3 [24576/60000 (41%)]\tLoss: 0.077848\n",
            "Train Epoch: 3 [28672/60000 (48%)]\tLoss: 0.062020\n",
            "Train Epoch: 3 [32768/60000 (55%)]\tLoss: 0.029776\n",
            "Train Epoch: 3 [36864/60000 (61%)]\tLoss: 0.083454\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.012400\n",
            "Train Epoch: 3 [45056/60000 (75%)]\tLoss: 0.146472\n",
            "Train Epoch: 3 [49152/60000 (82%)]\tLoss: 0.006347\n",
            "Train Epoch: 3 [53248/60000 (89%)]\tLoss: 0.039597\n",
            "Train Epoch: 3 [57344/60000 (96%)]\tLoss: 0.016163\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.056459\n",
            "Train Epoch: 4 [4096/60000 (7%)]\tLoss: 0.058724\n",
            "Train Epoch: 4 [8192/60000 (14%)]\tLoss: 0.004427\n",
            "Train Epoch: 4 [12288/60000 (20%)]\tLoss: 0.012400\n",
            "Train Epoch: 4 [16384/60000 (27%)]\tLoss: 0.091406\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.027676\n",
            "Train Epoch: 4 [24576/60000 (41%)]\tLoss: 0.010694\n",
            "Train Epoch: 4 [28672/60000 (48%)]\tLoss: 0.032795\n",
            "Train Epoch: 4 [32768/60000 (55%)]\tLoss: 0.045898\n",
            "Train Epoch: 4 [36864/60000 (61%)]\tLoss: 0.304801\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.059840\n",
            "Train Epoch: 4 [45056/60000 (75%)]\tLoss: 0.056993\n",
            "Train Epoch: 4 [49152/60000 (82%)]\tLoss: 0.073384\n",
            "Train Epoch: 4 [53248/60000 (89%)]\tLoss: 0.039259\n",
            "Train Epoch: 4 [57344/60000 (96%)]\tLoss: 0.059923\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.039279\n",
            "Train Epoch: 5 [4096/60000 (7%)]\tLoss: 0.034654\n",
            "Train Epoch: 5 [8192/60000 (14%)]\tLoss: 0.141508\n",
            "Train Epoch: 5 [12288/60000 (20%)]\tLoss: 0.015704\n",
            "Train Epoch: 5 [16384/60000 (27%)]\tLoss: 0.004475\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.011012\n",
            "Train Epoch: 5 [24576/60000 (41%)]\tLoss: 0.152250\n",
            "Train Epoch: 5 [28672/60000 (48%)]\tLoss: 0.109607\n",
            "Train Epoch: 5 [32768/60000 (55%)]\tLoss: 0.011523\n",
            "Train Epoch: 5 [36864/60000 (61%)]\tLoss: 0.073555\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.008240\n",
            "Train Epoch: 5 [45056/60000 (75%)]\tLoss: 0.026076\n",
            "Train Epoch: 5 [49152/60000 (82%)]\tLoss: 0.024626\n",
            "Train Epoch: 5 [53248/60000 (89%)]\tLoss: 0.077693\n",
            "Train Epoch: 5 [57344/60000 (96%)]\tLoss: 0.035050\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy: 9793/10000 (98)\n",
            "\n",
            "\n",
            "Adversarial Test: Accuracy: 6047/10000 (60)\n",
            "\n",
            "\n",
            "misclassified examples : 3806/ 10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eit5UQdPr8se",
        "colab_type": "code",
        "outputId": "b9c38969-38ff-4f7a-dd21-595641bf0d78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# data normalizationL True\n",
        "if __name__ == '__main__':\n",
        "  main(data_normalize=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.303055\n",
            "Train Epoch: 1 [4096/60000 (7%)]\tLoss: 0.248802\n",
            "Train Epoch: 1 [8192/60000 (14%)]\tLoss: 0.252149\n",
            "Train Epoch: 1 [12288/60000 (20%)]\tLoss: 0.186621\n",
            "Train Epoch: 1 [16384/60000 (27%)]\tLoss: 0.246582\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.278320\n",
            "Train Epoch: 1 [24576/60000 (41%)]\tLoss: 0.206446\n",
            "Train Epoch: 1 [28672/60000 (48%)]\tLoss: 0.158319\n",
            "Train Epoch: 1 [32768/60000 (55%)]\tLoss: 0.183013\n",
            "Train Epoch: 1 [36864/60000 (61%)]\tLoss: 0.114978\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.037682\n",
            "Train Epoch: 1 [45056/60000 (75%)]\tLoss: 0.044962\n",
            "Train Epoch: 1 [49152/60000 (82%)]\tLoss: 0.073879\n",
            "Train Epoch: 1 [53248/60000 (89%)]\tLoss: 0.088708\n",
            "Train Epoch: 1 [57344/60000 (96%)]\tLoss: 0.490714\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.166194\n",
            "Train Epoch: 2 [4096/60000 (7%)]\tLoss: 0.034445\n",
            "Train Epoch: 2 [8192/60000 (14%)]\tLoss: 0.170235\n",
            "Train Epoch: 2 [12288/60000 (20%)]\tLoss: 0.107106\n",
            "Train Epoch: 2 [16384/60000 (27%)]\tLoss: 0.063629\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.100274\n",
            "Train Epoch: 2 [24576/60000 (41%)]\tLoss: 0.104201\n",
            "Train Epoch: 2 [28672/60000 (48%)]\tLoss: 0.081487\n",
            "Train Epoch: 2 [32768/60000 (55%)]\tLoss: 0.126877\n",
            "Train Epoch: 2 [36864/60000 (61%)]\tLoss: 0.091228\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.105752\n",
            "Train Epoch: 2 [45056/60000 (75%)]\tLoss: 0.034252\n",
            "Train Epoch: 2 [49152/60000 (82%)]\tLoss: 0.069282\n",
            "Train Epoch: 2 [53248/60000 (89%)]\tLoss: 0.076305\n",
            "Train Epoch: 2 [57344/60000 (96%)]\tLoss: 0.061212\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.064569\n",
            "Train Epoch: 3 [4096/60000 (7%)]\tLoss: 0.076679\n",
            "Train Epoch: 3 [8192/60000 (14%)]\tLoss: 0.073347\n",
            "Train Epoch: 3 [12288/60000 (20%)]\tLoss: 0.053598\n",
            "Train Epoch: 3 [16384/60000 (27%)]\tLoss: 0.067666\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.049955\n",
            "Train Epoch: 3 [24576/60000 (41%)]\tLoss: 0.100137\n",
            "Train Epoch: 3 [28672/60000 (48%)]\tLoss: 0.045750\n",
            "Train Epoch: 3 [32768/60000 (55%)]\tLoss: 0.126770\n",
            "Train Epoch: 3 [36864/60000 (61%)]\tLoss: 0.014717\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.055635\n",
            "Train Epoch: 3 [45056/60000 (75%)]\tLoss: 0.097897\n",
            "Train Epoch: 3 [49152/60000 (82%)]\tLoss: 0.080630\n",
            "Train Epoch: 3 [53248/60000 (89%)]\tLoss: 0.021672\n",
            "Train Epoch: 3 [57344/60000 (96%)]\tLoss: 0.042913\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.017990\n",
            "Train Epoch: 4 [4096/60000 (7%)]\tLoss: 0.009505\n",
            "Train Epoch: 4 [8192/60000 (14%)]\tLoss: 0.031665\n",
            "Train Epoch: 4 [12288/60000 (20%)]\tLoss: 0.034033\n",
            "Train Epoch: 4 [16384/60000 (27%)]\tLoss: 0.005029\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.009235\n",
            "Train Epoch: 4 [24576/60000 (41%)]\tLoss: 0.044866\n",
            "Train Epoch: 4 [28672/60000 (48%)]\tLoss: 0.017261\n",
            "Train Epoch: 4 [32768/60000 (55%)]\tLoss: 0.008649\n",
            "Train Epoch: 4 [36864/60000 (61%)]\tLoss: 0.033220\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.237982\n",
            "Train Epoch: 4 [45056/60000 (75%)]\tLoss: 0.028334\n",
            "Train Epoch: 4 [49152/60000 (82%)]\tLoss: 0.049817\n",
            "Train Epoch: 4 [53248/60000 (89%)]\tLoss: 0.218258\n",
            "Train Epoch: 4 [57344/60000 (96%)]\tLoss: 0.072936\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.025630\n",
            "Train Epoch: 5 [4096/60000 (7%)]\tLoss: 0.037002\n",
            "Train Epoch: 5 [8192/60000 (14%)]\tLoss: 0.102961\n",
            "Train Epoch: 5 [12288/60000 (20%)]\tLoss: 0.055765\n",
            "Train Epoch: 5 [16384/60000 (27%)]\tLoss: 0.005155\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.093160\n",
            "Train Epoch: 5 [24576/60000 (41%)]\tLoss: 0.010894\n",
            "Train Epoch: 5 [28672/60000 (48%)]\tLoss: 0.006836\n",
            "Train Epoch: 5 [32768/60000 (55%)]\tLoss: 0.019928\n",
            "Train Epoch: 5 [36864/60000 (61%)]\tLoss: 0.102376\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.151764\n",
            "Train Epoch: 5 [45056/60000 (75%)]\tLoss: 0.002213\n",
            "Train Epoch: 5 [49152/60000 (82%)]\tLoss: 0.011566\n",
            "Train Epoch: 5 [53248/60000 (89%)]\tLoss: 0.002566\n",
            "Train Epoch: 5 [57344/60000 (96%)]\tLoss: 0.046533\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy: 9727/10000 (97)\n",
            "\n",
            "\n",
            "Adversarial Test: Accuracy: 8964/10000 (90)\n",
            "\n",
            "\n",
            "misclassified examples : 967/ 10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}